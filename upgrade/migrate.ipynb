{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from minio import Minio\n",
    "from datetime import datetime\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_with_dates(json_str):\n",
    "    data = json.loads(json_str)\n",
    "    # parse dates if needed\n",
    "    return data\n",
    "\n",
    "df = pd.read_csv(\"models.csv\")\n",
    "\n",
    "df['versions'] = df['versions'].apply(json.loads)\n",
    "df['files'] = df['files'].apply(json.loads)\n",
    "df['folders'] = df['folders'].apply(json.loads)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_client = Minio(\n",
    "\tendpoint=os.getenv('S3_ENDPOINT'),\n",
    "\taccess_key=os.getenv('ACCESS_KEY_ID'),\n",
    "\tsecret_key=os.getenv('SECRET_ACCESS_KEY'),\n",
    "\tsecure=True,\n",
    ")\n",
    "\n",
    "old_bucket = os.getenv('OLD_BUCKET')\n",
    "new_bucket = os.getenv('NEW_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "# \tfiles = minio_client.list_objects(new_bucket, row.id, recursive=True)\n",
    "# \tnames = [file.object_name for file in files]\n",
    "# \ttry:\n",
    "# \t\tassert f'{row.id}/catalog.v1.parquet' in names, f'{row.id} does not have a catalog.v1.parquet file'\n",
    "# \texcept:\n",
    "# \t\tprint(row.id, row.name)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version_id': 1, 'createdAt': '2023-11-03T16:12:06.732000', 'size': 44718151}\n",
      "{'name': 'model.onnx', 'size': 44717985, 'checksum': '3eec90939be13a739ce2d70424391a5956c54e95', 'version': 1, 'versions': [1], 'createdAt': '2023-11-03T16:12:06.738000'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/Desktop/eotdl/.venv/lib/python3.12/site-packages/geopandas/array.py:968: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 0]),  # minx\n",
      "/Users/juan/Desktop/eotdl/.venv/lib/python3.12/site-packages/geopandas/array.py:969: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmin(b[:, 1]),  # miny\n",
      "/Users/juan/Desktop/eotdl/.venv/lib/python3.12/site-packages/geopandas/array.py:970: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 2]),  # maxx\n",
      "/Users/juan/Desktop/eotdl/.venv/lib/python3.12/site-packages/geopandas/array.py:971: RuntimeWarning: All-NaN slice encountered\n",
      "  np.nanmax(b[:, 3]),  # maxy\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Polygon\n",
    "import geopandas as gpd\n",
    "import random\n",
    "import rasterio as rio\n",
    "\n",
    "files_map = []\n",
    "for row in df.iterrows():\n",
    "\tdataset_id = row[1]['id']\n",
    "\tdataset_name = row[1]['name']\n",
    "\tversions = row[1]['versions']\n",
    "\tfiles = row[1]['files']\n",
    "\tfolders = row[1]['folders']\n",
    "\t# print(dataset_id, dataset_name, versions, files, folders)\n",
    "\t# print(dataset_id, json.loads(files))\n",
    "\t# if len(json.loads(versions)) <= 1:\n",
    "\t# \tcontinue\n",
    "\tfor version in json.loads(versions):\n",
    "\t\tprint(version)\n",
    "\t\tdata = []\n",
    "\t\tfor file in json.loads(files):\n",
    "\t\t\tif not version['version_id'] in file['versions']:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tprint(file)\n",
    "\t\t\titem_id = file['name']\n",
    "\t\t\tif file['version'] > 1:\n",
    "\t\t\t\t\titem_id = f'{file[\"name\"]}-{random.randint(1, 1000000)}'\n",
    "\t\t\t\t\tprint(file['name'], '->', item_id)\n",
    "\t\t\tstac_item  = {\n",
    "\t\t\t\t'type': 'Feature',\n",
    "\t\t\t\t'stac_version': '1.0.0',\n",
    "\t\t\t\t'stac_extensions': [],\n",
    "\t\t\t\t'datetime': datetime.now(),  # must be native timestamp (https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#timestamp)\n",
    "\t\t\t\t'id': item_id,\n",
    "\t\t\t\t'bbox': {\n",
    "\t\t\t\t\t'xmin': 0.0,\n",
    "\t\t\t\t\t'ymin': 0.0,\n",
    "\t\t\t\t\t'xmax': 0.0,\n",
    "\t\t\t\t\t'ymax': 0.0\n",
    "\t\t\t\t}, # infer from file or from list of geometries\n",
    "\t\t\t\t'geometry': Polygon(), # empty polygon\n",
    "\t\t\t\t'assets': { 'asset': { # STAC needs this to be a Dict[str, Asset], not list !!! use same key or parquet breaks !!!\n",
    "\t\t\t\t\t'href': f'https://dev.api.eotdl.com/models/{dataset_id}/stage/{item_id}', # TODO: change to prod\n",
    "\t\t\t\t\t'checksum': file['checksum'],\n",
    "\t\t\t\t\t'timestamp': file['createdAt'],\n",
    "\t\t\t\t\t'size': file['size'],\n",
    "\t\t\t\t}},\n",
    "\t\t\t\t\"links\": [],\n",
    "\t\t\t\t# 'collection': 'source',\n",
    "\t\t\t\t# anything below are properties (need at least one!)\n",
    "\t\t\t\t'repository': 'eotdl',\t\t\t\t\n",
    "\t\t\t}\n",
    "\t\t\tdata.append(stac_item)\n",
    "\t\t\t# copy file from old bucket to new bucket\n",
    "\t\t\tminio_client.fget_object(\n",
    "\t\t\t\told_bucket,\n",
    "\t\t\t\tf'{dataset_id}/{file['name']}_{file['version']}',\n",
    "\t\t\t\tf'{dataset_id}/{item_id}'\n",
    "\t\t\t)\n",
    "\t\t\tminio_client.fput_object(\n",
    "\t\t\t\tnew_bucket,\n",
    "\t\t\t\tf'{dataset_id}/{item_id}',\n",
    "\t\t\t\tf'{dataset_id}/{item_id}'\n",
    "\t\t\t)\n",
    "\t\t\tfiles_map.append((f'{dataset_id}/{file['name']}_{file['version']}', f'{dataset_id}/{item_id}'))\n",
    "\t\tif data:\n",
    "\t\t\tgdf = gpd.GeoDataFrame(data, geometry='geometry')\n",
    "\t\t\tcatalog_name = f'catalog.v{version[\"version_id\"]}.parquet'\n",
    "\t\t\tgdf.to_parquet(catalog_name)\n",
    "\t\t\t# copy parquet to bucket\n",
    "\t\t\tminio_client.fput_object(\n",
    "\t\t\t\tnew_bucket,\n",
    "\t\t\t\tf'{dataset_id}/{catalog_name}',\n",
    "\t\t\t\tcatalog_name\n",
    "\t\t\t)\n",
    "\tbreak\n",
    "\t\n",
    "_df = pd.DataFrame(files_map, columns=['old_path', 'new_path'])\n",
    "# _df.to_csv('files_map.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.read_csv('files_map.csv')\n",
    "# _df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = gpd.read_parquet('catalog.v3.parquet')\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = minio_client.list_objects(new_bucket)\n",
    "# for file in files:\n",
    "# \tprint(file.object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65f407248e68180349152973/\n",
      "65f407248e68180349152973/catalog.v1.parquet\n",
      "65f407248e68180349152973/catalog.v2.parquet\n",
      "65f407248e68180349152973/model.onnx\n",
      "65f407248e68180349152973/unet-resnet50.onnx\n"
     ]
    }
   ],
   "source": [
    "# get all files in bucket/id\n",
    "\n",
    "files = minio_client.list_objects(new_bucket, '65f407248e68180349152973', recursive=True)\n",
    "for file in files:\n",
    "\tprint(file.object_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
