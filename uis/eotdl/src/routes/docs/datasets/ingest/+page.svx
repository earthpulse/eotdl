<script>
	import Api from "../../components/Api.svelte";
	import CLI from "../../components/CLI.svelte";
	import UI from "../../components/UI.svelte";
	import Code from "../../components/Code.svelte";
	import BadgeWarning from "../../BadgeWarning.svelte";
</script>

<BadgeWarning>Currently, only Q0 datasets (.zip files) are supported.</BadgeWarning>

Learn more about the datasets [quality levels](/docs/datasets/quality).

# Ingest datasets

You can upload your own datasets to the EOTDL platform. 

The following constraints apply to the dataset name:
- It must be unique
- It must be between 3 and 45 characters long
- It can only contain alphanumeric characters and dashes.

Once a dataset is ingested, it cannot be deleted since other users may be using it in their own pipelines. However, you can update a dataset by ingesting a new version of it.

> ⚠ Up until versioning is not supported, this may also affect other users pipelines.

## User interface

<UI>Use the INGEST button in the <a href="/datasets" class="text-green-200 hover:underline">datasets</a> page.</UI>

You'll need to be logged in to ingest datasets.

Tou can use the `EDIT` button of the dataset page to update the information or data.

## API 

You can ingest a dataset using the following API call:

<Api><Code>curl -X 'POST' \
  'https://api.eotdl.com/datasets' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer {'<'}your-token> \
  -H 'Content-Type: multipart/form-data' \
  -F 'file=@{'<'}dataset-path>;type=application/zip' \
  -F 'name={'<'}dataset-name>' \
  -F 'author={'<'}dataset-author>' \
  -F 'link={'<'}dataset-link>' \
  -F 'license={'<'}dataset-license>' \
  -F 'description={'<'}dataset-description>'</Code></Api>

> ⚠ These instructions work well for small datasets, but for the ingestion of large datasets (> 1 GB) we recommend using the CLI.

In order to update the a dataset, use the following call

<Api><Code>curl -X 'POST' \
  'https://api.eotdl.com/datasets' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer {'<'}your-token> \
  -H 'Content-Type: multipart/form-data' \
  -F 'file=@{'<'}dataset-path>;type=application/zip' \
  -F 'dataset_id={'<'}dataset-id>'
  -F 'name={'<'}dataset-name>' \
  -F 'author={'<'}dataset-author>' \
  -F 'link={'<'}dataset-link>' \
  -F 'license={'<'}dataset-license>' \
  -F 'description={'<'}dataset-description>'</Code></Api>

In this case, all fields excpet for `dataset_id` are optional.

## CLI 

You can ingest a dataset using the following CLI command:

<CLI><Code>eotdl-cli datasets ingest {'<'}dataset-path> {'<'}dataset-name></Code></CLI>

> After uploading a dataset with the CLI we recommend visiting the dataset page to fill in the rest of the information.

<!-- For very large datasets, parallel ingestion can speed up the process. Use the `--p` flag to indicate the number of threads to use (use `-1` to use all).

<CLI><Code>eotdl-cli datasets ingest {'<'}dataset-path> --p 4</Code></CLI>

> ⚠ This feature may not work on all platforms, and may cause the ingestion to fail. If this happens, try again without the `--p` flag or a lower value. -->

In order to update a dataset, use the following command

<CLI><Code>eotdl-cli datasets update {'<'}dataset-name> {'<'}dataset-path></Code></CLI>
