{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like training datasets, ML Models in EOTDL are categorized into different [quality levels](https://eotdl.com/docs/datasets/quality), which in turn will impact the range of functionality that will be available for each model.\n",
    "\n",
    "In this tutorial you will learn about Q2 models, models with STAC metadata and the ML-Model extension (models with STAC metadata but not ML-Model extension will be qualified as Q1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAC Spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Q2 ML Models we rely on the [ML-Model](https://github.com/crim-ca/mlm-extension) STAC extension. Here we develop the required metadata for the [RoadSegmentation](https://www.eotdl.com/models/RoadSegmentation) Q0 model on EOTDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024.05.02'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eotdl\n",
    "\n",
    "eotdl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model `RoadSegmentation v2` already exists at data/RoadSegmentation/v2. To force download, use force=True or -f in the CLI.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/RoadSegmentation/v2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eotdl.models import download_model\n",
    "\n",
    "try:\n",
    "\tpath = download_model('RoadSegmentation', path=\"data\", version=2)\n",
    "except Exception as e:\n",
    "\tprint(e)\n",
    "\tpath = 'data/RoadSegmentation/v2'\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md', 'model.onnx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to provide STAC metadata to run `model.onnx` on any inference processor that implements the ML-Model STAC extension. From the official repo:\n",
    "\n",
    "> The STAC Machine Learning Model (MLM) Extension provides a standard set of fields to describe machine learning models trained on overhead imagery and enable running model inference.\n",
    ">\n",
    "> The main objectives of the extension are:\n",
    ">\n",
    "> 1. to enable building model collections that can be searched alongside associated STAC datasets\n",
    "> 2. record all necessary bands, parameters, modeling artifact locations, and high-level processing steps to deploy an inference service.\n",
    ">\n",
    ">Specifically, this extension records the following information to make ML models searchable and reusable:\n",
    ">\n",
    "> 1. Sensor band specifications\n",
    "> 2. Model input transforms including resize and normalization\n",
    "> 3. Model output shape, data type, and its semantic interpretation\n",
    "> 4. An optional, flexible description of the runtime environment to be able to run the model\n",
    "> 5. Scientific references\n",
    "\n",
    "Let's start with a generic `catalog` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "\n",
    "# current directory + 'data/RoadSegmentation/STAC'\n",
    "root_href = os.path.join(os.getcwd(), 'data/RoadSegmentation/STAC')\n",
    "\n",
    "catalog = pystac.Catalog(id='RoadSegmentationQ2', description='Catalog for the Road Segmentation Q2 ML Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a `collection` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<style>\n",
       ".pystac-summary {\n",
       "    cursor: pointer;\n",
       "    display:list-item;\n",
       "}\n",
       ".pystac-key {\n",
       "    color: rgb(0, 128, 0);\n",
       "    font-weight: 700;\n",
       "}\n",
       ".pystac-key-value {\n",
       "    display: inline-block;\n",
       "    margin: 0px 0.5em 0px 0px;\n",
       "}\n",
       "</style>\n",
       "<div class=\"jp-RenderedJSON jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div class=\"container\" style=\"line-height: normal;\">\n",
       "        <ul style=\"padding: 0px; margin: 0px; list-style: none; display: block;\">\n",
       "            \n",
       "                \n",
       "                    \n",
       "        <li style=\"overflow-wrap: break-word; padding-left: 2.125em; text-indent: -0.5em;\">\n",
       "            <span class=\"pystac-key pystac-key-value\">rel</span>\n",
       "            <span style=\"color: rgb(186, 33, 33);\">\"child\"</span>\n",
       "        </li>\n",
       "    \n",
       "                \n",
       "            \n",
       "                \n",
       "                    \n",
       "        <li style=\"overflow-wrap: break-word; padding-left: 2.125em; text-indent: -0.5em;\">\n",
       "            <span class=\"pystac-key pystac-key-value\">href</span>\n",
       "            <span style=\"color: rgb(186, 33, 33);\">None</span>\n",
       "        </li>\n",
       "    \n",
       "                \n",
       "            \n",
       "                \n",
       "                    \n",
       "        <li style=\"overflow-wrap: break-word; padding-left: 2.125em; text-indent: -0.5em;\">\n",
       "            <span class=\"pystac-key pystac-key-value\">type</span>\n",
       "            <span style=\"color: rgb(186, 33, 33);\">\"application/json\"</span>\n",
       "        </li>\n",
       "    \n",
       "                \n",
       "            \n",
       "        </ul>\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Link rel=child target=<Collection id=model>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pystac\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a new Collection\n",
    "collection = pystac.Collection(\n",
    "    id='model',\n",
    "    description='Collection for the Road Segmentation Q2 ML Model',\n",
    "    extent=pystac.Extent(\n",
    "        spatial=pystac.SpatialExtent([[-180, -90, 180, 90]]), # dummy extent\n",
    "        temporal=pystac.TemporalExtent([[datetime(2020, 1, 1), None]]) # dummy extent\n",
    "    ),\n",
    "\t# extra_fields={\n",
    "    #     'stac_extensions': ['https://crim-ca.github.io/mlm-extension/v1.2.0/schema.json']\n",
    "    # }\n",
    ")\n",
    "\n",
    "# Add the Collection to the Catalog\n",
    "catalog.add_child(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, an `item` to describe the model itself with the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "<style>\n",
       ".pystac-summary {\n",
       "    cursor: pointer;\n",
       "    display:list-item;\n",
       "}\n",
       ".pystac-key {\n",
       "    color: rgb(0, 128, 0);\n",
       "    font-weight: 700;\n",
       "}\n",
       ".pystac-key-value {\n",
       "    display: inline-block;\n",
       "    margin: 0px 0.5em 0px 0px;\n",
       "}\n",
       "</style>\n",
       "<div class=\"jp-RenderedJSON jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div class=\"container\" style=\"line-height: normal;\">\n",
       "        <ul style=\"padding: 0px; margin: 0px; list-style: none; display: block;\">\n",
       "            \n",
       "                \n",
       "                    \n",
       "        <li style=\"overflow-wrap: break-word; padding-left: 2.125em; text-indent: -0.5em;\">\n",
       "            <span class=\"pystac-key pystac-key-value\">rel</span>\n",
       "            <span style=\"color: rgb(186, 33, 33);\">\"item\"</span>\n",
       "        </li>\n",
       "    \n",
       "                \n",
       "            \n",
       "                \n",
       "                    \n",
       "        <li style=\"overflow-wrap: break-word; padding-left: 2.125em; text-indent: -0.5em;\">\n",
       "            <span class=\"pystac-key pystac-key-value\">href</span>\n",
       "            <span style=\"color: rgb(186, 33, 33);\">None</span>\n",
       "        </li>\n",
       "    \n",
       "                \n",
       "            \n",
       "                \n",
       "                    \n",
       "        <li style=\"overflow-wrap: break-word; padding-left: 2.125em; text-indent: -0.5em;\">\n",
       "            <span class=\"pystac-key pystac-key-value\">type</span>\n",
       "            <span style=\"color: rgb(186, 33, 33);\">\"application/json\"</span>\n",
       "        </li>\n",
       "    \n",
       "                \n",
       "            \n",
       "        </ul>\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Link rel=item target=<Item id=model>>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new Item\n",
    "item = pystac.Item(\n",
    "    id='model',\n",
    "    geometry={ # dummy geometry\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [125.6, 10.1]\n",
    "    },\n",
    "    bbox=[125.6, 10.1, 125.6, 10.1], # dummy bbox\n",
    "    datetime=datetime.utcnow(), # dummy datetime\n",
    "    properties={ \n",
    "\t\t\"mlm:name\": \"model.onnx\", # name of the asset ? otherwise, how can we know which asset to use ?\n",
    "\t\t\"mlm:framework\": \"ONNX\",  # only framework support for now\n",
    "\t\t\"mlm:architecture\": \"U-Net\",\n",
    "\t\t\"mlm:tasks\": [\"segmentation\"], # https://github.com/crim-ca/mlm-extension?tab=readme-ov-file#task-enum\n",
    "\t\t\"mlm:input\": { # https://github.com/crim-ca/mlm-extension?tab=readme-ov-file#model-input-object\n",
    "\t\t\t\"name\": \"RGB statellite image (HR)\",\n",
    "\t\t\t\"bands\": [\n",
    "\t\t\t\t\"red\",\n",
    "\t\t\t\t\"green\",\n",
    "\t\t\t\t\"blue\"\n",
    "\t\t\t],\n",
    "\t\t\t\"input\": { # https://github.com/crim-ca/mlm-extension?tab=readme-ov-file#input-structure-object\n",
    "\t\t\t\t\"shape\": [\n",
    "\t\t\t\t\t-1,\n",
    "\t\t\t\t\t3,\n",
    "\t\t\t\t\t-1, # should be divisble by 16\n",
    "\t\t\t\t\t-1 # should be divisble by 16\n",
    "\t\t\t\t],\n",
    "\t\t\t\t\"dim_order\": [\n",
    "\t\t\t\t\t\"batch\",\n",
    "\t\t\t\t\t\"channel\",\n",
    "\t\t\t\t\t\"height\",\n",
    "\t\t\t\t\t\"width\"\n",
    "\t\t\t\t],\n",
    "\t\t\t\t\"data_type\": \"float32\",\n",
    "                # we should add here the resize to nearest divisible by 16\n",
    "\t\t\t\t# \"pre_processing_function\": { # https://github.com/crim-ca/mlm-extension?tab=readme-ov-file#processing-expression\n",
    "\t\t\t\t# \t\"format\": \n",
    "\t\t\t\t# \t\"expression\": \n",
    "\t\t\t\t# }\n",
    "\t\t\t\t\"description\": \"Model trained with 1024x1024 RGB HR images, but can work with other dimensions as long as they are divisible by 16\"\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t\"mlm:output\": {\n",
    "\t\t\t\"name\": \"road binary mask\",\n",
    "\t\t\t\"tasks\": [\"segmentation\"], # redundant ?\n",
    "\t\t\t\"result\": { # https://github.com/crim-ca/mlm-extension?tab=readme-ov-file#result-structure-object\n",
    "\t\t\t\t\"shape\": [-1, -1, -1],\n",
    "\t\t\t\t\"dim_order\": [\n",
    "\t\t\t\t\t\"batch\",\n",
    "\t\t\t\t\t\"height\",\n",
    "\t\t\t\t\t\"width\"\n",
    "\t\t\t\t],\n",
    "\t\t\t\t\"data_type\": \"uint8\",\n",
    "\t\t\t\t\"description\": \"Binary mask of the road segmentation. 1 for road, 0 for background\",\n",
    "\t\t\t\t# \"post_processing_function\": { # https://github.com/crim-ca/mlm-extension?tab=readme-ov-file#processing-expression\n",
    "\t\t\t\t# }\n",
    "\t\t\t},\n",
    "\t\t},\n",
    "\t}, \n",
    "    stac_extensions=['https://crim-ca.github.io/mlm-extension/v1.2.0/schema.json']\n",
    ")\n",
    "\n",
    "# Add the Item to the Collection\n",
    "collection.add_item(item)\n",
    "\n",
    "# Save the Catalog to a file\n",
    "# catalog.normalize_and_save(root_href=root_href, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model weights are added as an asset to the item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Asset\n",
    "model_asset = pystac.Asset(\n",
    "    href=os.path.abspath('data/RoadSegmentation/v2/model.onnx'), \n",
    ")\n",
    "\n",
    "# Add the Asset to the Item\n",
    "item.add_asset('model', model_asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we validate and save the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the Catalog\n",
    "\n",
    "# catalog.validate_all()\n",
    "\n",
    "catalog.normalize_and_save(root_href=root_href, catalog_type=pystac.CatalogType.SELF_CONTAINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eotdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
