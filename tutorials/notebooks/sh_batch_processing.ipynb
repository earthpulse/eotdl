{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel Hub Batch Processing\n",
    "\n",
    "**Sentinel Hub Batch Processing** takes the geometry of a large area and divides it according to a specified tile grid. Next, it executes processing requests for each tile in the grid and stores results to a given location at AWS S3 storage. All this is efficiently executed on the server-side. Because of the optimized performance, it is significantly faster than running the same process locally. \n",
    "\n",
    "More information about batch processing is available at Sentinel Hub documentation pages:\n",
    "\n",
    "- [How Batch API works](https://docs.sentinel-hub.com/api/latest/api/batch/)\n",
    "- [Batch API service description](https://docs.sentinel-hub.com/api/latest/reference/#tag/batch_process)\n",
    "\n",
    "\n",
    "The tutorial will show a standard process of using Batch Processing with `sentinelhub-py`. The process can be divided into:\n",
    "\n",
    "1. Define and create a batch request\n",
    "2. Analyse a batch request before it is executed\n",
    "3. Run a batch requests job and check the outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from sentinelhub import (\n",
    "    CRS,\n",
    "    DataCollection,\n",
    "    Geometry,\n",
    "    MimeType,\n",
    "    SentinelHubBatch,\n",
    "    SentinelHubRequest,\n",
    "    SHConfig,\n",
    "    bbox_to_dimensions,\n",
    "    monitor_batch_job,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a batch request\n",
    "\n",
    "To create a batch request we need to do the following:\n",
    "\n",
    "- Define a Process API request which we would like to execute on a large area.\n",
    "- Select a tiling grid which will define how our area will be split into smaller tiles.\n",
    "- Set up an S3 bucket where results will be saved.\n",
    "\n",
    "\n",
    "### 1.1 Define a Process API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = SHConfig()\n",
    "\n",
    "if config.sh_client_id == \"\" or config.sh_client_secret == \"\":\n",
    "    print(\"Warning! To use Sentinel Hub Process API, please provide the credentials (client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our area of interest, we'll take an area of crop fields in California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SHAPE = \"\"\"{\n",
    "\"type\": \"FeatureCollection\",\n",
    "\"name\": \"california_crop_fields\",\n",
    "\"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" } },\n",
    "\"features\": [\n",
    "{ \"type\": \"Feature\", \"properties\": { \"name\": \"Entire area\" }, \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -119.2089, 36.1383 ], [ -119.1323, 36.0980 ], [ -119.1282, 35.9869 ], [ -119.2264, 35.9532 ], [ -119.3263, 35.9822 ], [ -119.3488, 36.0899 ], [ -119.2089, 36.1383 ] ] ] ] } },\n",
    "{ \"type\": \"Feature\", \"properties\": { \"name\": \"Test sub-area\" }, \"geometry\": { \"type\": \"MultiPolygon\", \"coordinates\": [ [ [ [ -119.2778, 36.0806 ], [ -119.2776, 36.04 ], [ -119.2135, 36.04 ], [ -119.21409, 36.0806 ], [ -119.2778, 36.0806 ] ] ] ] } }\n",
    "]\n",
    "}\"\"\"\n",
    "area_gdf = gpd.read_file(SHAPE)\n",
    "\n",
    "# Geometry of an entire area\n",
    "full_geometry = Geometry(area_gdf.geometry.values[0], crs=CRS.WGS84)\n",
    "# Bounding box of a test sub-area\n",
    "test_bbox = Geometry(area_gdf.geometry.values[1], crs=CRS.WGS84).bbox\n",
    "\n",
    "area_gdf.plot(column=\"name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define function for plotting RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_image(\n",
    "    image: np.ndarray, factor: float = 1.0, clip_range: tuple[float, float] | None = None, **kwargs: Any\n",
    ") -> None:\n",
    "    \"\"\"Utility function for plotting RGB images.\"\"\"\n",
    "    _, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n",
    "    if clip_range is not None:\n",
    "        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n",
    "    else:\n",
    "        ax.imshow(image * factor, **kwargs)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a true-color satellite image of the entire area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evalscript_true_color = \"\"\"\n",
    "    //VERSION=3\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\", \"B03\", \"B04\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 3\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B04, sample.B03, sample.B02];\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "request = SentinelHubRequest(\n",
    "    evalscript=evalscript_true_color,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A,\n",
    "        )\n",
    "    ],\n",
    "    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "    geometry=full_geometry,\n",
    "    size=(512, 512),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "image = request.get_data()[0]\n",
    "\n",
    "plot_image(image, factor=3.5 / 255, clip_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define an evalscript and time range. To better demonstrate the power of batch processing we'll take an evalscript that returns a temporally-interpolated stack NDVI values.\n",
    "\n",
    "In the following cell parameters `evalscript` and `time_interval` are both defined for the same time interval. If you decide to change the time interval you have to change it both in the cell and in the evalscript code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evalscript = \"\"\"\n",
    "//VERSION=3\n",
    "\n",
    "// Calculate number of bands needed for all intervals\n",
    "// Initialize dates and interval\n",
    "// Beware: in JS months are 0 indexed\n",
    "var start_date = new Date(2023, 6, 1, 0, 0, 0);\n",
    "var end_date = new Date(2023, 6, 30, 0, 0, 0);\n",
    "var sampled_dates = sample_timestamps(start_date, end_date, 7, 'day').map(d => withoutTime(d));\n",
    "var nb_bands = sampled_dates.length;\n",
    "var n_valid = 0;\n",
    "var n_all = 0;\n",
    "\n",
    "function interval_search(x, arr) {\n",
    "  let start_idx = 0,  end_idx = arr.length - 2;\n",
    "\n",
    "  // Iterate while start not meets end\n",
    "  while (start_idx <= end_idx) {\n",
    "    // Find the mid index\n",
    "    let mid_idx = (start_idx + end_idx) >> 1;\n",
    "\n",
    "    // If element is present at mid, return True\n",
    "    if (arr[mid_idx] <= x && x < arr[mid_idx + 1]) {\n",
    "      return mid_idx;\n",
    "    }\n",
    "    // Else look in left or right half accordingly\n",
    "    else if (arr[mid_idx + 1] <= x) start_idx = mid_idx + 1;\n",
    "    else end_idx = mid_idx - 1;\n",
    "  }\n",
    "  if (x == arr[arr.length-1]){\n",
    "    return arr.length-2;\n",
    "  }\n",
    "  return undefined;\n",
    "}\n",
    "\n",
    "function linearInterpolation(x, x0, y0, x1, y1, no_data_value=NaN) {\n",
    "  if (x < x0 || x > x1) {\n",
    "    return no_data_value;\n",
    "  }\n",
    "  var a = (y1 - y0) / (x1 - x0);\n",
    "  var b = -a * x0 + y0;\n",
    "  return a * x + b;\n",
    "}\n",
    "\n",
    "function lininterp(x_arr, xp_arr, fp_arr, no_data_value=NaN) {\n",
    "  results = [];\n",
    "  data_mask = [];\n",
    "  xp_arr_idx = 0;\n",
    "  for (var i=0; i<x_arr.length; i++) {\n",
    "    var x = x_arr[i];\n",
    "    n_all+=1;\n",
    "    interval = interval_search(x, xp_arr);\n",
    "    if (interval === undefined) {\n",
    "      data_mask.push(0);\n",
    "      results.push(no_data_value);\n",
    "      continue;\n",
    "    }\n",
    "    data_mask.push(1);\n",
    "    n_valid+=1;\n",
    "    results.push(\n",
    "      linearInterpolation(\n",
    "        x,\n",
    "        xp_arr[interval],\n",
    "        fp_arr[interval],\n",
    "        xp_arr[interval+1],\n",
    "        fp_arr[interval+1],\n",
    "        no_data_value\n",
    "      )\n",
    "    );\n",
    "  }\n",
    "  return [results, data_mask];\n",
    "}\n",
    "\n",
    "function interpolated_index(index_a, index_b) {\n",
    "  // Calculates the index for all bands in array\n",
    "  var index_data = [];\n",
    "  for (var i = 0; i < index_a.length; i++){\n",
    "     // UINT index returned\n",
    "     let ind = (index_a[i] - index_b[i]) / (index_a[i] + index_b[i]);\n",
    "     index_data.push(ind * 10000 + 10000);\n",
    "  }\n",
    "  return index_data\n",
    "}\n",
    "\n",
    "function increase(original_date, period, period_unit) {\n",
    "    date = new Date(original_date)\n",
    "    switch (period_unit) {\n",
    "        case 'millisecond':\n",
    "            return new Date(date.setMilliseconds(date.getMilliseconds()+period));\n",
    "        case 'second':\n",
    "            return new Date(date.setSeconds(date.getSeconds()+period));\n",
    "        case 'minute':\n",
    "            return new Date(date.setMinutes(date.getMinutes()+period));\n",
    "        case 'hour':\n",
    "            return new Date(date.setHours(date.getHours()+period));\n",
    "        case 'day':\n",
    "            return new Date(date.setDate(date.getDate()+period));\n",
    "        case 'month':\n",
    "            return new Date(date.setMonth(date.getMonth()+period));\n",
    "        default:\n",
    "            return undefined\n",
    "    }\n",
    "}\n",
    "\n",
    "function sample_timestamps(start, end, period, period_unit) {\n",
    "    var cDate = new Date(start);\n",
    "    var sampled_dates = []\n",
    "    while (cDate < end) {\n",
    "        sampled_dates.push(cDate);\n",
    "        cDate = increase(cDate, period, period_unit);\n",
    "    }\n",
    "    return sampled_dates;\n",
    "}\n",
    "\n",
    "function is_valid(smp) {\n",
    "  // Check if the sample is valid (i.e. contains no clouds or snow)\n",
    "  let clm = smp.CLM;\n",
    "  let dm = smp.dataMask;\n",
    "\n",
    "  if (clm === 1 || clm === 255) {\n",
    "        return false;\n",
    "  }\n",
    "  if (dm !=1 ) {\n",
    "        return false;\n",
    "  }\n",
    "  return true;\n",
    "}\n",
    "\n",
    "function withoutTime(intime) {\n",
    "  // Return date without time\n",
    "  intime.setHours(0, 0, 0, 0);\n",
    "  return intime;\n",
    "}\n",
    "\n",
    "// Sentinel Hub functions\n",
    "function setup() {\n",
    "  // Setup input/output parameters\n",
    "    return {\n",
    "        input: [{\n",
    "            bands: [\"B04\", \"B08\", \"CLM\", \"dataMask\"],\n",
    "            units: \"DN\"\n",
    "        }],\n",
    "      output: [\n",
    "          {id: \"NDVI\", bands: nb_bands, sampleType: SampleType.UINT16},\n",
    "          {id: \"data_mask\", bands: nb_bands, sampleType: SampleType.UINT8}\n",
    "      ],\n",
    "    mosaicking: \"ORBIT\"\n",
    "    }\n",
    "}\n",
    "\n",
    "// Evaluate pixels in the bands\n",
    "function evaluatePixel(samples, scenes) {\n",
    "\n",
    "  // Initialise arrays\n",
    "  var valid_samples = {'B04':[], 'B08':[]};\n",
    "\n",
    "  var valid_dates = []\n",
    "  // Loop over samples.\n",
    "  for (var i = samples.length-1; i >= 0; i--){\n",
    "      if (is_valid(samples[i])) {\n",
    "        valid_dates.push(withoutTime(new Date(scenes[i].date)));\n",
    "        valid_samples['B04'].push(samples[i].B04);\n",
    "        valid_samples['B08'].push(samples[i].B08);\n",
    "      }\n",
    "  }\n",
    "\n",
    "  // Calculate indices and return optimised for UINT16 format (will need unpacking)\n",
    "  var ndvi = interpolated_index(valid_samples['B08'], valid_samples['B04'])\n",
    "\n",
    "  var [ndvi_interpolated, dm] = lininterp(sampled_dates, valid_dates, ndvi, 0);\n",
    "\n",
    "  // Return all arrays\n",
    "  return {\n",
    "    NDVI: ndvi,\n",
    "    data_mask: dm\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_interval = dt.date(year=2023, month=7, day=1), dt.date(year=2023, month=7, day=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a Process API request and test it on a smaller sub-area to make sure we get back desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentinelhub_request = SentinelHubRequest(\n",
    "    evalscript=evalscript,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            time_interval=time_interval,\n",
    "        )\n",
    "    ],\n",
    "    responses=[\n",
    "        SentinelHubRequest.output_response(\"NDVI\", MimeType.TIFF),\n",
    "        SentinelHubRequest.output_response(\"data_mask\", MimeType.TIFF),\n",
    "    ],\n",
    "    bbox=test_bbox,\n",
    "    size=bbox_to_dimensions(test_bbox, 10),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "results = sentinelhub_request.get_data()[0]\n",
    "\n",
    "print(f\"Output data: {list(results)}\")\n",
    "plot_image(results[\"NDVI.tif\"][..., 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained stacks of NDVI values and data masks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define a batch client\n",
    "\n",
    "The interface for Sentinel Hub Batch API is class `SentinelHubBatch`. We initialize it with a configuration object that contains credentials and URLs of the services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = SentinelHubBatch(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Select a tiling grid\n",
    "\n",
    "Batch API offers a number of pre-defined tiling grids. We can check which ones are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(batch.iter_tiling_grids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a 10km grid, which is based on Sentinel-2 data tiling grid in UTM coordinate reference systems.\n",
    "\n",
    "There is also an option to check a definition for a single grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify grid ID here:\n",
    "GRID_ID = 1\n",
    "\n",
    "batch.get_tiling_grid(GRID_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Set up an S3 bucket\n",
    "\n",
    "For this step please follow [instructions](https://docs.sentinel-hub.com/api/latest/api/batch/#aws-s3-bucket-settings) on how to configure an S3 bucket in a way that Sentinel Hub service will be able to write to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write bucket name here:\n",
    "BUCKET_NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Join batch request definition\n",
    "\n",
    "Now we are ready to create an entire batch request. This step won't trigger the actual processing. It will only save a batch request definition to the server-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentinelhub_request = SentinelHubRequest(\n",
    "    evalscript=evalscript,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            time_interval=time_interval,\n",
    "        )\n",
    "    ],\n",
    "    responses=[\n",
    "        SentinelHubRequest.output_response(\"NDVI\", MimeType.TIFF),\n",
    "        SentinelHubRequest.output_response(\"data_mask\", MimeType.TIFF),\n",
    "    ],\n",
    "    geometry=full_geometry,\n",
    "    # This time we don't specify size parameter\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "batch_request = batch.create(\n",
    "    sentinelhub_request,\n",
    "    tiling_grid=SentinelHubBatch.tiling_grid(grid_id=GRID_ID, resolution=10, buffer=(50, 50)),\n",
    "    bucket_name=BUCKET_NAME,\n",
    "    description=\"NDVI batch job\",\n",
    ")\n",
    "\n",
    "batch_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A batch request has been successfully created. The information about a request is provided in the form of a `BatchRequest` dataclass object. From the object representation, we can see some of its main properties, such as `status`, which defines the current status of a batch request. \n",
    "\n",
    "We can also check its full payload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_request.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse a batch request\n",
    "\n",
    "Before we run a batch request job we can check currently defined batch requests and run an analysis to determine the outcome of a batch request. Important information we can obtain from this step are:\n",
    "\n",
    "- the exact geometries of tiles from a tiling grid that will be processed,\n",
    "- the number of processing units that a batch job will cost.\n",
    "\n",
    "Note that this analysis paragraph is optional and is not required to run a batch request job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Run an analysis\n",
    "\n",
    "At the moment we don't have information about tiles or processing units yet. But we can order the service to calculate it.\n",
    "\n",
    "The following will start the analysis on the server-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch.start_analysis(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of our batch request it might take from a few seconds to a few minutes for analysis to finish. To determine if the analysis has finished we have to update batch request info and check the `status` information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_request = batch.get_request(batch_request)\n",
    "\n",
    "batch_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once analysis is completed the `valueEstimate` tells us an estimated number of processing units the batch job will cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Running this batch job will take about {batch_request.value_estimate:.4f} processing units\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Check tile definitions\n",
    "\n",
    "When the analysis is complete we can check information about tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tile_info in batch.iter_tiles(batch_request):\n",
    "    print(tile_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, we can request information about a single tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a tile ID\n",
    "TILE_ID = \"\"\n",
    "\n",
    "batch.get_tile(batch_request, TILE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with tiles we can also use a type of an `AreaSplitter` class which already parses geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentinelhub import BatchSplitter\n",
    "\n",
    "splitter = BatchSplitter(batch_request=batch_request, config=config)\n",
    "splitter.get_bbox_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_batch_splitter(splitter):\n",
    "    \"\"\"Plots tiles and area geometry from a splitter class\"\"\"\n",
    "    tile_geometries = [Geometry(bbox.geometry, bbox.crs) for bbox in splitter.get_bbox_list()]\n",
    "    tile_geometries = [geometry.transform(splitter.crs) for geometry in tile_geometries]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        {\"status\": [info[\"status\"] for info in splitter.get_info_list()]},\n",
    "        geometry=[geometry.geometry for geometry in tile_geometries],\n",
    "        crs=splitter.crs.pyproj_crs(),\n",
    "    )\n",
    "    gdf = gdf.dissolve(by=\"status\").reset_index()\n",
    "    color_map = {\n",
    "        \"PROCESSED\": \"tab:green\",\n",
    "        \"FAILED\": \"tab:red\",\n",
    "        \"PENDING\": \"tab:blue\",\n",
    "        \"SCHEDULED\": \"tab:cyan\",\n",
    "    }\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(10, 10))\n",
    "    pmarks = []\n",
    "\n",
    "    for status, sdf in gdf.groupby(\"status\"):\n",
    "        sdf.plot(ax=ax, color=color_map[status], label=status)\n",
    "        pmarks.append(Patch(facecolor=color_map[status], label=status))\n",
    "\n",
    "    area_series = gpd.GeoSeries([splitter.get_area_shape()], crs=splitter.crs.pyproj_crs())\n",
    "    area_series.plot(ax=ax, facecolor=\"none\", edgecolor=\"black\")\n",
    "\n",
    "    handles, _ = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=[*handles, *pmarks], loc=\"lower right\")\n",
    "\n",
    "\n",
    "plot_batch_splitter(splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a batch request job\n",
    "\n",
    "Once we decide to run a batch request job we can trigger it with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch.start_job(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can check if a job has finished by updating batch request info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_request = batch.get_request(batch_request)\n",
    "\n",
    "batch_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package also provides a utility function that monitors batch job execution by periodically checking for status of all tiles and sleeping in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "monitor_batch_job(batch_request, config=config, sleep_time=60)  # It will update progress every 60 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to check which results have already been saved to the given S3 bucket.\n",
    "\n",
    "When the job is running we can decide at any time to cancel it. Results that have already been produced will remain on the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.cancel_job(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a job has finished we can check the status in batch request info and statuses of each tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splitter = BatchSplitter(batch_request=batch_request, config=config)\n",
    "\n",
    "plot_batch_splitter(splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case processing for any tile fails we have an option to re-run the job again. This will only run the processing for the tiles that failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.restart_job(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can re-run processing only for a single tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an ID of a tile that failed\n",
    "FAILED_TILE_ID = \"\"\n",
    "\n",
    "batch.reprocess_tile(batch_request, FAILED_TILE_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-eotdl-2024.5.2",
   "language": "python",
   "name": "conda-env-users-eotdl-2024.5.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
