{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting a Q0 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is now ready to be ingested to EOTDL. We just need to add the general metadata of the dataset in a README file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"---\n",
    "name: Sentinel-2-Ships\n",
    "authors: \n",
    "  - Pierre-Jean Coquard\n",
    "license: free\n",
    "source: https://github.com/earthpulse/eotdl/tree/main/tutorials/usecases/useCaseD\n",
    "---\n",
    "\n",
    "# Sentinel-2-Ships\n",
    "\n",
    "This is an example dataset created for the use case D.\n",
    "\"\"\"\n",
    "\n",
    "with open(\"data/sentinel_2/README.md\", \"w\") as outfile:\n",
    "    outfile.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading directory data/sentinel_2...\n",
      "generating list of files to upload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 234/234 [00:00<00:00, 10976.42it/s]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "No new files to upload",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meotdl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ingest_dataset\n\u001b[0;32m----> 3\u001b[0m \u001b[43mingest_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/sentinel_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/datasets/ingest.py:29\u001b[0m, in \u001b[0;36mingest_dataset\u001b[0;34m(path, verbose, logger, force_metadata_update, sync_metadata)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalog.json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m path\u001b[38;5;241m.\u001b[39miterdir()]:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ingest_stac(path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalog.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mingest_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_metadata_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msync_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/auth/auth.py:61\u001b[0m, in \u001b[0;36mwith_auth.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     user \u001b[38;5;241m=\u001b[39m auth()\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/datasets/ingest.py:83\u001b[0m, in \u001b[0;36mingest_folder\u001b[0;34m(folder, verbose, logger, force_metadata_update, sync_metadata, user)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_metadata:\n\u001b[1;32m     82\u001b[0m     update_dataset(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m], metadata, content, user)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mingest_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/files/ingest.py:107\u001b[0m, in \u001b[0;36mingest_files\u001b[0;34m(repo, dataset_or_model_id, folder, verbose, logger, user, endpoint)\u001b[0m\n\u001b[1;32m    105\u001b[0m items \u001b[38;5;241m=\u001b[39m retrieve_files(folder)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# retrieve files\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m upload_files, existing_files, large_files \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_files_lists\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_or_model_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m logger(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(upload_files)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(large_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m new files will be ingested\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m logger(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(existing_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files already exist in dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/files/ingest.py:91\u001b[0m, in \u001b[0;36mgenerate_files_lists\u001b[0;34m(items, folder, dataset_or_model_id, endpoint, logger, max_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# TODO: should ingest new version if files removed\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(upload_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(large_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo new files to upload\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m upload_files, existing_files, large_files\n",
      "\u001b[0;31mException\u001b[0m: No new files to upload"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset(\"data/sentinel_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can upgrade this dataset to a Q1 dataset by adding STAC metadata. We use the `STACCGenerator` class to automaticaly generate the STAC metadata for the whole dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eotdl.curation.stac.stac import STACGenerator\n",
    "from eotdl.curation.stac.assets import STACAssetGenerator\n",
    "from eotdl.curation.stac.parsers import UnestructuredParser\n",
    "from eotdl.curation.stac.dataframe_labeling import UnlabeledStrategy, LabeledStrategy\n",
    "\n",
    "stac_generator = STACGenerator(item_parser=UnestructuredParser, \n",
    "                               assets_generator=STACAssetGenerator, \n",
    "                               labeling_strategy=LabeledStrategy,\n",
    "                               image_format='tif'\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>ix</th>\n",
       "      <th>collection</th>\n",
       "      <th>extensions</th>\n",
       "      <th>bands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/sentinel_2/ship_210017000_2022-08-12.tif</td>\n",
       "      <td>ship</td>\n",
       "      <td>0</td>\n",
       "      <td>data/sentinel_2/sentinel-2-ships</td>\n",
       "      <td>(proj, raster, eo)</td>\n",
       "      <td>(B01, B02, B03, B04, B05, B06, B07, B08, B09, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/sentinel_2/ship_219024604_2022-08-25.tif</td>\n",
       "      <td>ship</td>\n",
       "      <td>0</td>\n",
       "      <td>data/sentinel_2/sentinel-2-ships</td>\n",
       "      <td>(proj, raster, eo)</td>\n",
       "      <td>(B01, B02, B03, B04, B05, B06, B07, B08, B09, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/sentinel_2/ship_311000277_2022-08-25.tif</td>\n",
       "      <td>ship</td>\n",
       "      <td>0</td>\n",
       "      <td>data/sentinel_2/sentinel-2-ships</td>\n",
       "      <td>(proj, raster, eo)</td>\n",
       "      <td>(B01, B02, B03, B04, B05, B06, B07, B08, B09, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/sentinel_2/ship_265859000_2022-08-25.tif</td>\n",
       "      <td>ship</td>\n",
       "      <td>0</td>\n",
       "      <td>data/sentinel_2/sentinel-2-ships</td>\n",
       "      <td>(proj, raster, eo)</td>\n",
       "      <td>(B01, B02, B03, B04, B05, B06, B07, B08, B09, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/sentinel_2/ship_211367180_2022-08-12.tif</td>\n",
       "      <td>ship</td>\n",
       "      <td>0</td>\n",
       "      <td>data/sentinel_2/sentinel-2-ships</td>\n",
       "      <td>(proj, raster, eo)</td>\n",
       "      <td>(B01, B02, B03, B04, B05, B06, B07, B08, B09, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image label  ix  \\\n",
       "0  data/sentinel_2/ship_210017000_2022-08-12.tif  ship   0   \n",
       "1  data/sentinel_2/ship_219024604_2022-08-25.tif  ship   0   \n",
       "2  data/sentinel_2/ship_311000277_2022-08-25.tif  ship   0   \n",
       "3  data/sentinel_2/ship_265859000_2022-08-25.tif  ship   0   \n",
       "4  data/sentinel_2/ship_211367180_2022-08-12.tif  ship   0   \n",
       "\n",
       "                         collection          extensions  \\\n",
       "0  data/sentinel_2/sentinel-2-ships  (proj, raster, eo)   \n",
       "1  data/sentinel_2/sentinel-2-ships  (proj, raster, eo)   \n",
       "2  data/sentinel_2/sentinel-2-ships  (proj, raster, eo)   \n",
       "3  data/sentinel_2/sentinel-2-ships  (proj, raster, eo)   \n",
       "4  data/sentinel_2/sentinel-2-ships  (proj, raster, eo)   \n",
       "\n",
       "                                               bands  \n",
       "0  (B01, B02, B03, B04, B05, B06, B07, B08, B09, ...  \n",
       "1  (B01, B02, B03, B04, B05, B06, B07, B08, B09, ...  \n",
       "2  (B01, B02, B03, B04, B05, B06, B07, B08, B09, ...  \n",
       "3  (B01, B02, B03, B04, B05, B06, B07, B08, B09, ...  \n",
       "4  (B01, B02, B03, B04, B05, B06, B07, B08, B09, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extensions = {'ship': ('proj', 'raster', 'eo')}\n",
    "bands = {'ship': ('B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B11', 'B12')}\n",
    "collection = {'ship': 'sentinel-2-ships'}\n",
    "\n",
    "df = stac_generator.get_stac_dataframe('data/sentinel_2', collections=collection, extensions=extensions, bands=bands)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then generate the Stac metadata from the `STACDataframe` generated during the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sentinel-2-ships collection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:00<00:00, 173.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating and saving catalog...\n",
      "Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stac_generator.generate_stac_metadata(stac_id='ship-segmentation-dataset',\n",
    "                                      description='Ship segmentation dataset',\n",
    "                                      output_folder='data/sentinel_2_stac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add the STAC metadata for the labels :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating labels collection...: 77it [00:00, 1405.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success on labels generation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eotdl.curation.stac.extensions import ScaneoLabeler\n",
    "\n",
    "labeler = ScaneoLabeler()\n",
    "\n",
    "catalog = 'data/sentinel_2_stac/catalog.json'\n",
    "labels_extra_properties = {'label_methods': [\"automated\"]}\n",
    "labeler.generate_stac_labels(\n",
    "    catalog=catalog,\n",
    "    root_folder='data/sentinel_2',\n",
    "    collection='sentinel-2-ships',\n",
    "    label_type=\"raster\",\n",
    "    **labels_extra_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the STAC metadata is successfully generated, we can ingest the Q1 dataset into EOTDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STAC catalog...\n",
      "New version created, version: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:31<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting STAC catalog...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset('data/sentinel_2_stac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating splits...\n",
      "Total size: 77\n",
      "Train size: 61\n",
      "Test size: 7\n",
      "Validation size: 7\n",
      "Generating Training split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:00<00:00, 11309.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Validation split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 11142.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 11920.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success on splits generation!\n",
      "Validating and saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from eotdl.curation.stac.extensions import add_ml_extension\n",
    "import pystac\n",
    "catalog = 'data/sentinel_2_stac/catalog.json'\n",
    "\n",
    "add_ml_extension(\n",
    "\tcatalog,\n",
    "\tdestination='data/sentinel_2_q2',\n",
    "\tsplits=True,\n",
    "\tsplits_collection_id=\"labels\",\n",
    "\tname='Ship Segmentation Q2',\n",
    "\ttasks=['segmentation'],\n",
    "\tinputs_type=['satellite imagery'],\n",
    "\tannotations_type='raster',\n",
    "\tversion='0.1.0',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the quality metrics for the dataset to ensure that it can be ingested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looking for spatial duplicates...: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looking for spatial duplicates...: 308it [00:00, 5778.80it/s]\n",
      "Calculating classes balance...: 308it [00:00, 310838.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating and saving...\n",
      "Success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eotdl.curation.stac.extensions import MLDatasetQualityMetrics\n",
    "\n",
    "catalog = 'data/sentinel_2_q2/catalog.json'\n",
    "\n",
    "MLDatasetQualityMetrics.calculate(catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally ingest the Q2 dataset into EOTDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading STAC catalog...\n",
      "New version created, version: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:59<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting STAC catalog...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "[Errno 2] No such file or directory: '/home/pcoquard/git/eotdl_use_case_d/data/sentinel_2_q2/catalog.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meotdl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ingest_dataset\n\u001b[0;32m----> 3\u001b[0m \u001b[43mingest_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/sentinel_2_q2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/datasets/ingest.py:28\u001b[0m, in \u001b[0;36mingest_dataset\u001b[0;34m(path, verbose, logger, force_metadata_update, sync_metadata)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath must be a folder\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalog.json\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [f\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m path\u001b[38;5;241m.\u001b[39miterdir()]:\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mingest_stac\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcatalog.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ingest_folder(path, verbose, logger, force_metadata_update, sync_metadata)\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/auth/auth.py:61\u001b[0m, in \u001b[0;36mwith_auth.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     60\u001b[0m     user \u001b[38;5;241m=\u001b[39m auth()\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/eotdl3.9/lib/python3.9/site-packages/eotdl/datasets/ingest.py:166\u001b[0m, in \u001b[0;36mingest_stac\u001b[0;34m(stac_catalog, logger, user)\u001b[0m\n\u001b[1;32m    163\u001b[0m data, error \u001b[38;5;241m=\u001b[39m repo\u001b[38;5;241m.\u001b[39mingest_stac(json\u001b[38;5;241m.\u001b[39mloads(df\u001b[38;5;241m.\u001b[39mto_json()), dataset_id, user)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# TODO: delete all assets that were uploaded\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error)\n\u001b[1;32m    167\u001b[0m logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: [Errno 2] No such file or directory: '/home/pcoquard/git/eotdl_use_case_d/data/sentinel_2_q2/catalog.json'"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset('data/sentinel_2_q2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eotdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
