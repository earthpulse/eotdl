{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest an existing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to showcase how to ingest an existing dataset into EOTDL.\n",
    "\n",
    "Once your dataset is ingested, you can use it in the same way as any other dataset in EOTDL (exploring, training, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting through the CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended version to ingest a dataset is using the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1meotdl datasets ingest [OPTIONS]\u001b[0m\u001b[1m                                        \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[31m*\u001b[0m  \u001b[1;36m-\u001b[0m\u001b[1;36m-path\u001b[0m     \u001b[1;32m-p\u001b[0m      \u001b[1;33mPATH\u001b[0m  Path to dataset \u001b[2m[default: None]\u001b[0m \u001b[2;31m[required]\u001b[0m       \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-verbose\u001b[0m          \u001b[1;33m    \u001b[0m  Verbose output                                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m             \u001b[1;33m    \u001b[0m  Show this message and exit.                      \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets ingest --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ingest a dataset you will need a folder in your system with the data you want to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boadella.geojson  dates.csv  EuroSAT-small  sample_stacdataframe.csv\n"
     ]
    }
   ],
   "source": [
    "!ls workshop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we are going to work with a subsample of the [EuroSAT](https://www.eotdl.com/datasets/EuroSAT-RGB) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workshop_data/EuroSAT-small/metadata.yml',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_3.tif',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_1.tif',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_2.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_3.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_1.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_2.tif']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob \n",
    "\n",
    "files = glob('workshop_data/EuroSAT-small/**/*.*', recursive=True)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `metadata.yml` file is required for Q0 datasets, containing some basic required information (dataset authors, licens, link to source and dataset name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors:\n",
      "- Patrick Helber\n",
      "license: open\n",
      "source: http://madm.dfki.de/downloads\n",
      "name: EuroSAT-small\n"
     ]
    }
   ],
   "source": [
    "!cat workshop_data/EuroSAT-small/metadata.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen name is the one that will appear in the repository, hence it must be unique, between 3 and 45 characters long and can only contain alphanumeric characters and dashes (learn more at [https://www.eotdl.com/docs/datasets/ingest](https://www.eotdl.com/docs/datasets/ingest)).\n",
    "\n",
    "Trying to ingest a dataset without a `metadata.yml` file will fail.\n",
    "\n",
    "If everything is correct, the ingestion process should suceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading directory workshop_data/EuroSAT-small...\n",
      "Uploading files: 100%|█████████████████████████| 6/6 [00:15<00:00,  2.67s/files]\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets ingest -p workshop_data/EuroSAT-small/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now your dataset is avilable at EOTDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EuroSAT-small']\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets list -n eurosat-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since the `EuroSAT-small` name is already taken, this process should fail for you. To solve it, just upload the dataset with a different name. However, this will polute the EOTDL with test datasets so we encourage you to try the ingestion process with a real dataset that you want to ingest (or overwrite your test dataset in the future with useful data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ingest Q1+ datasets, a valid STAC catalog is required instead of the `metadata.yml` file. We will explore this in the [data curation](tutorials/workshops/bids23/05_STAC_metadata.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, every time you re-upload a dataset a new version is created. \n",
    "\n",
    "When you download a dataset, the latest version is used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 6/6 [00:15<00:00,  2.62s/file]\n",
      "Data available at /home/juan/.cache/eotdl/datasets/EuroSAT-small/v3/AnnualCrop\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets get EuroSAT-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can specify the version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 6/6 [00:22<00:00,  3.73s/file]\n",
      "Data available at /home/juan/.cache/eotdl/datasets/EuroSAT-small/v1/AnnualCrop\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets get EuroSAT-small -v 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1  v2\tv3\n"
     ]
    }
   ],
   "source": [
    "!ls $HOME/.cache/eotdl/datasets/EuroSAT-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply versioning at dataset and file level, meaning only new or modified files will be uploaded in future re-uploads, downloading the appropriate files for each version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting through the Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ingest datasets using the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading directory workshop_data/EuroSAT-small...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading files: 100%|██████████| 6/6 [00:00<00:00,  6.03files/s]\n"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "ingest_dataset(\"workshop_data/EuroSAT-small\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting through the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingesting a dataset through the API is a multi step process:\n",
    "\n",
    "1. Create/Retrieve a dataset\n",
    "2. Create a version\n",
    "3. Ingest files (optionally, retrieve files to avoid uploading the same file)\n",
    "\n",
    "The library/CLI will take care of these steps, so it is the recommended way to ingest a dataset. \n",
    "\n",
    "However, if you still want to ingest datasets with the API, first you'll need to authenticate as shown in the [exploring](tutorials/workshops/bids23/01_exploring.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6ImUtdHB2cDI4NEZlX1pfVzVZRUpfaiJ9.eyJuaWNrbmFtZSI6Iml0IiwibmFtZSI6Iml0QGVhcnRocHVsc2UuZXMiLCJwaWN0dXJlIjoiaHR0cHM6Ly9zLmdyYXZhdGFyLmNvbS9hdmF0YXIvNjU1NzQxYmI2ZDkzMDNmNjljMGY2YTUzYmU2MjMwZDQ_cz00ODAmcj1wZyZkPWh0dHBzJTNBJTJGJTJGY2RuLmF1dGgwLmNvbSUyRmF2YXRhcnMlMkZpdC5wbmciLCJ1cGRhdGVkX2F0IjoiMjAyMy0xMC0yNVQxMDoxMDowNy4yMDdaIiwiZW1haWwiOiJpdEBlYXJ0aHB1bHNlLmVzIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImlzcyI6Imh0dHBzOi8vZWFydGhwdWxzZS5ldS5hdXRoMC5jb20vIiwiYXVkIjoic0M1V2Zsem1Qb2owNThGSllMMmNrRU51dHhKTDRQVFciLCJpYXQiOjE2OTgyMzY4NTEsImV4cCI6MTY5ODI3Mjg1MSwic3ViIjoiYXV0aDB8NjE2YjAwNTdhZjBjNzUwMDY5MWEwMjZlIn0.m1KC287ISsi4ckObFvIM1PjKn0AbF-ZQPYwxHAhGYwLDqgOw-d5gclgcaM2JS-qjxeyQ1baJTdI1Ym17Ou-bZkUZkSu47JputasxQ8jj39d6_r4ys9j6XooKQJqOgk0g8sZgd-QFUdhYNjbZZr3PiFJEOGWZ6sZKBs84COfoqw7X2mS27OwcldId9VUUd4XRRjJ7Q97L4LBuj8zQIZL4NiCWaWth9WOahm6UcJtMFDlxJl7ocK2NkPePHuSy1_vBpJ0rxr4c3aPk3A913QM1Bhr8CMnKiZI0kibQKqVEuKqRuddoBfA_YYSkyoLfGSo8FmHf8EZOrnzihOns-d0NLQ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a dataset passing the required metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detail': 'Dataset already exists'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "\t'https://api.eotdl.com/datasets',\n",
    "\theaders={'Authorization': f'Bearer {token}'},\n",
    "\tjson={\n",
    "\t\t'name': 'EuroSAT-small',\n",
    "\t\t\"authors\": [\"author1\", \"author2\"],\n",
    "\t\t\"source\": \"https://link-to-source\",\n",
    "\t\t\"license\": \"the-license\"\n",
    "\t}\n",
    ")\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset already exists, and you want to ingest a new version, you'll have to retrieve its information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 'auth0|616b0057af0c7500691a026e',\n",
       " 'id': '6526accffd974011abc2413a',\n",
       " 'name': 'EuroSAT-small',\n",
       " 'authors': ['juan'],\n",
       " 'source': 'http://km.com',\n",
       " 'license': 'open',\n",
       " 'files': '6526accffd974011abc2413b',\n",
       " 'versions': [{'version_id': 1,\n",
       "   'createdAt': '2023-10-11T16:08:47.864',\n",
       "   'size': 643464},\n",
       "  {'version_id': 2, 'createdAt': '2023-10-11T16:08:47.864', 'size': 643464},\n",
       "  {'version_id': 3, 'createdAt': '2023-10-12T07:14:16.642', 'size': 643464},\n",
       "  {'version_id': 4, 'createdAt': '2023-10-12T07:14:16.642', 'size': 643464},\n",
       "  {'version_id': 5, 'createdAt': '2023-10-12T07:14:16.642', 'size': 643464},\n",
       "  {'version_id': 6, 'createdAt': '2023-10-12T07:14:16.642', 'size': 643464}],\n",
       " 'description': '',\n",
       " 'tags': [],\n",
       " 'createdAt': '2023-10-11T16:08:47.865',\n",
       " 'updatedAt': '2023-10-25T14:21:57.986',\n",
       " 'likes': 0,\n",
       " 'downloads': 0,\n",
       " 'quality': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get('https://api.eotdl.com/datasets?name=EuroSAT-small')\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_id': '6526accffd974011abc2413a', 'version': 8}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = response.json()['id']\n",
    "response = requests.post(\n",
    "\tf'https://api.eotdl.com/datasets/version/{dataset_id}',\n",
    "\theaders={'Authorization': f'Bearer {token}'},\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can ingest all the files that you want to this version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workshop_data/EuroSAT-small/metadata.yml',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_3.tif',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_1.tif',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_2.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_3.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_1.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_2.tif']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO: ingest through API, can we simplify?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eotdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
