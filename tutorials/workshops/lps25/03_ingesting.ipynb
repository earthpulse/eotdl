{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest an existing Dataset or Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to showcase how to ingest an existing dataset or model into EOTDL.\n",
    "\n",
    "Once it is ingested, you can use it in the same way as any other dataset or model in EOTDL (exploring, staging, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting through the CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended way to ingest a dataset is using the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1meotdl datasets ingest [OPTIONS]\u001b[0m\u001b[1m                                        \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " Ingest a dataset to the EOTDL.asdf                                             \n",
      "                                                                                \n",
      " \u001b[2mThis command ingests the dataset to the EOTDL. The dataset must be a folder \u001b[0m   \n",
      " \u001b[2mwith the dataset files, and at least a README.md file (and a catalog.json file\u001b[0m \n",
      " \u001b[2mfor Q1+). If these files are missing, the ingestion will not work. All the \u001b[0m    \n",
      " \u001b[2mfiles in the folder will be uploaded to the EOTDL.\u001b[0m                             \n",
      "                                                                                \n",
      " \u001b[2mThe following constraints apply to the dataset name:\u001b[0m                           \n",
      " \u001b[2m- It must be unique\u001b[0m                                                            \n",
      " \u001b[2m- It must be between 3 and 45 characters long\u001b[0m                                  \n",
      " \u001b[2m- It can only contain alphanumeric characters and dashes.\u001b[0m                      \n",
      "                                                                                \n",
      " \u001b[2mThe README.md file must contain the following fields in the metadata header:\u001b[0m   \n",
      " \u001b[2m- name: the name of the dataset\u001b[0m                                                \n",
      " \u001b[2m- authors: the author or authors of the dataset\u001b[0m                                \n",
      " \u001b[2m- license: the license of the dataset\u001b[0m                                          \n",
      " \u001b[2m- source: the source of the dataset\u001b[0m                                            \n",
      " \u001b[2m- thumbnail: an image to use as the thumbnail of the dataset in the website\u001b[0m    \n",
      " \u001b[2mThe rest of the content in the README.md file will be used as the description \u001b[0m \n",
      " \u001b[2mof the dataset in the website. If using \u001b[0m\u001b[1;2;36m-\u001b[0m\u001b[1;2;36m-verbose\u001b[0m\u001b[2m, it will print the progress \u001b[0m \n",
      " \u001b[2mof the ingestion.\u001b[0m                                                              \n",
      "                                                                                \n",
      " \u001b[2mExamples\u001b[0m                                                                       \n",
      " \u001b[1;2;36m--------\u001b[0m                                                                       \n",
      " \u001b[2m$ eotdl dataset ingest \u001b[0m\u001b[1;2;36m-\u001b[0m\u001b[1;2;36m-path\u001b[0m\u001b[2m /path/to/folder-with-dataset \u001b[0m\u001b[1;2;36m-\u001b[0m\u001b[1;2;36m-verbose\u001b[0m\u001b[2m True\u001b[0m      \n",
      "                                                                                \n",
      "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m───────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
      "\u001b[2m│\u001b[0m \u001b[31m*\u001b[0m  \u001b[1;36m-\u001b[0m\u001b[1;36m-path\u001b[0m     \u001b[1;32m-p\u001b[0m       \u001b[1;33mPATH\u001b[0m  Path to the dataset to ingest \u001b[2m[default: None]\u001b[0m   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                              \u001b[2;31m[required]                   \u001b[0m                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-verbose\u001b[0m  \u001b[1;32m-v\u001b[0m       \u001b[1;33m    \u001b[0m  Verbose output. This will print the progress of \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                              the ingestion                                   \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-force\u001b[0m    \u001b[1;32m-f\u001b[0m       \u001b[1;33m    \u001b[0m  Force metadata update even if it already        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                              exists. Will overwrite the current metadata in  \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                              EOTDL                                           \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-sync\u001b[0m     \u001b[1;32m-s\u001b[0m       \u001b[1;33m    \u001b[0m  Sync local metadata with the EOTDL. Will        \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m                              overwrite the local metadata                    \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-private\u001b[0m  \u001b[1;32m-pr\u001b[0m      \u001b[1;33m    \u001b[0m  Make dataset private                            \u001b[2m│\u001b[0m\n",
      "\u001b[2m│\u001b[0m    \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m              \u001b[1;33m    \u001b[0m  Show this message and exit.                     \u001b[2m│\u001b[0m\n",
      "\u001b[2m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets ingest --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to ingest a dataset you will need a folder in your system with the data you want to upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boadella_bbox.geojson  dates.csv      sample_stacdataframe.csv\n",
      "boadella.geojson       EuroSAT-small\n"
     ]
    }
   ],
   "source": [
    "!ls workshop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we are going to work with a subsample of the [EuroSAT](https://www.eotdl.com/datasets/EuroSAT-RGB) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workshop_data/EuroSAT-small/README.md',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_1.tif',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_2.tif',\n",
       " 'workshop_data/EuroSAT-small/Forest/Forest_3.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_1.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_3.tif',\n",
       " 'workshop_data/EuroSAT-small/AnnualCrop/AnnualCrop_2.tif']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob \n",
    "\n",
    "files = glob('workshop_data/EuroSAT-small/**/*.*', recursive=True)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `README.md` file is required for datasets and models, containing some basic required information (dataset authors, licens, link to source and dataset name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "authors:\n",
      "- Patrick Helber\n",
      "license: open\n",
      "source: http://madm.dfki.de/downloads\n",
      "name: EuroSAT-small-lps25\n",
      "---\n",
      "\n",
      "# EuroSAT small\n",
      "\n",
      "This is a test datasets used for the PhiLab24 workshop. It is a subset of the EuroSAT dataset."
     ]
    }
   ],
   "source": [
    "!cat workshop_data/EuroSAT-small/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen name is the one that will appear in the repository, hence it must be unique, between 3 and 45 characters long and can only contain alphanumeric characters and dashes (learn more at [https://www.eotdl.com/docs/datasets/ingest](https://www.eotdl.com/docs/datasets/ingest)).\n",
    "\n",
    "Trying to ingest a dataset without a `README.md` file will fail.\n",
    "\n",
    "If everything is correct, the ingestion process should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting directory: workshop_data/EuroSAT-small\n",
      "Ingesting files: 100%|████████████████████████████| 7/7 [00:03<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets ingest -p workshop_data/EuroSAT-small/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now your dataset is avilable at EOTDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EuroSAT-small-lps25']\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets list -n eurosat-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since the `EuroSAT-small-lps25` name is already taken, this process should fail for you. To solve it, just upload the dataset with a different name. However, this will polute the EOTDL with test datasets so we encourage you to try the ingestion process with a real dataset that you want to ingest (or overwrite your test dataset in the future with useful data). In any case, you can always delete the dataset from the EOTDL using the `DELETE` button in the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the ingestion process, a `catalog.parquet` file is created with STAC metadata. If your dataset already has STAC metadata (a `catalog.json` file exists at the root of the dataset), the metadata will be parsed and added to the `catalog.parquet` file. Otherwise, the `CLI` will create a STAC-compatible metadata from the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>stac_version</th>\n",
       "      <th>stac_extensions</th>\n",
       "      <th>datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>geometry</th>\n",
       "      <th>assets</th>\n",
       "      <th>links</th>\n",
       "      <th>repository</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.256343</td>\n",
       "      <td>README.md</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': '7274627b4d30c5e274b4c5...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.256534</td>\n",
       "      <td>Forest/Forest_1.tif</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': 'f3b8b9fef6b2df6f24792e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.256758</td>\n",
       "      <td>Forest/Forest_2.tif</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': '2e38dab64435bfbab25bab...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.256970</td>\n",
       "      <td>Forest/Forest_3.tif</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': '3e7bb982f9db5f7dabc556...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.257172</td>\n",
       "      <td>AnnualCrop/AnnualCrop_1.tif</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': '63bf72ad806aa6ae313eaf...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.257386</td>\n",
       "      <td>AnnualCrop/AnnualCrop_3.tif</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': '59330fce6d0bf01078db3d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Feature</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-06-20 11:03:56.257574</td>\n",
       "      <td>AnnualCrop/AnnualCrop_2.tif</td>\n",
       "      <td>{'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...</td>\n",
       "      <td>POLYGON EMPTY</td>\n",
       "      <td>{'asset': {'checksum': 'c406cb8920858b98898b9e...</td>\n",
       "      <td>[]</td>\n",
       "      <td>eotdl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type stac_version stac_extensions                   datetime  \\\n",
       "0  Feature        1.0.0              [] 2025-06-20 11:03:56.256343   \n",
       "1  Feature        1.0.0              [] 2025-06-20 11:03:56.256534   \n",
       "2  Feature        1.0.0              [] 2025-06-20 11:03:56.256758   \n",
       "3  Feature        1.0.0              [] 2025-06-20 11:03:56.256970   \n",
       "4  Feature        1.0.0              [] 2025-06-20 11:03:56.257172   \n",
       "5  Feature        1.0.0              [] 2025-06-20 11:03:56.257386   \n",
       "6  Feature        1.0.0              [] 2025-06-20 11:03:56.257574   \n",
       "\n",
       "                            id  \\\n",
       "0                    README.md   \n",
       "1          Forest/Forest_1.tif   \n",
       "2          Forest/Forest_2.tif   \n",
       "3          Forest/Forest_3.tif   \n",
       "4  AnnualCrop/AnnualCrop_1.tif   \n",
       "5  AnnualCrop/AnnualCrop_3.tif   \n",
       "6  AnnualCrop/AnnualCrop_2.tif   \n",
       "\n",
       "                                                bbox       geometry  \\\n",
       "0  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "1  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "2  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "3  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "4  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "5  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "6  {'xmax': 0.0, 'xmin': 0.0, 'ymax': 0.0, 'ymin'...  POLYGON EMPTY   \n",
       "\n",
       "                                              assets links repository  \n",
       "0  {'asset': {'checksum': '7274627b4d30c5e274b4c5...    []      eotdl  \n",
       "1  {'asset': {'checksum': 'f3b8b9fef6b2df6f24792e...    []      eotdl  \n",
       "2  {'asset': {'checksum': '2e38dab64435bfbab25bab...    []      eotdl  \n",
       "3  {'asset': {'checksum': '3e7bb982f9db5f7dabc556...    []      eotdl  \n",
       "4  {'asset': {'checksum': '63bf72ad806aa6ae313eaf...    []      eotdl  \n",
       "5  {'asset': {'checksum': '59330fce6d0bf01078db3d...    []      eotdl  \n",
       "6  {'asset': {'checksum': 'c406cb8920858b98898b9e...    []      eotdl  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "catalog = gpd.read_parquet('workshop_data/EuroSAT-small/catalog.parquet')\n",
    "\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now ingest the model that we trained in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/model.onnx\n"
     ]
    }
   ],
   "source": [
    "!ls outputs/*.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create the `README.md` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"---\n",
    "name: EuroSAT-RGB-lps25\n",
    "authors: \n",
    "  - Juan B. Pedro\n",
    "license: open\n",
    "source: https://github.com/earthpulse/eotdl/blob/develop/tutorials/workshops/lps25/02_training.ipynb\n",
    "---\n",
    "\n",
    "# EuroSAT-RGB-lps25\n",
    "\n",
    "This is a toy model trained with the EuroSAT dataset for the LPS25 workshop.\n",
    "\"\"\"\n",
    "\n",
    "with open('outputs/README.md', 'w') as outfile:\n",
    "\toutfile.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can ingest the model to EOTDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting directory: outputs\n",
      "Ingesting files: 100%|████████████████████████████| 2/2 [00:02<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "!eotdl models ingest -p outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EuroSAT-RGB-lps25']\n"
     ]
    }
   ],
   "source": [
    "!eotdl models list -n lps25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, every time you re-upload a dataset or model a new version is created. We apply versioning at dataset/model and file level, meaning only new or modified files will be uploaded in future re-uploads, downloading the appropriate files for each version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting directory: workshop_data/EuroSAT-small\n",
      "Ingesting files: 100%|████████████████████████████| 8/8 [00:02<00:00,  3.73it/s]\n",
      "A new version was created, your dataset has changed.\n",
      "Num changes: 1\n"
     ]
    }
   ],
   "source": [
    "!echo \"hello\" > workshop_data/EuroSAT-small/hello.txt\n",
    "!eotdl datasets ingest -p workshop_data/EuroSAT-small/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you stage a dataset, the latest version is used by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data available at /home/juan/.cache/eotdl/datasets/EuroSAT-small-lps25\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets get EuroSAT-small-lps25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can specify the version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data available at /home/juan/.cache/eotdl/datasets/EuroSAT-small-lps25\n"
     ]
    }
   ],
   "source": [
    "!eotdl datasets get EuroSAT-small-lps25 -v 1 -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catalog.v1.parquet  catalog.v2.parquet\tREADME.md\n"
     ]
    }
   ],
   "source": [
    "!ls $HOME/.cache/eotdl/datasets/EuroSAT-small-lps25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore the different versions in the user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting through the Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ingest datasets and models using the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting directory: workshop_data/EuroSAT-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting files: 100%|██████████| 8/8 [00:01<00:00,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new version was created, your dataset has not changed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eotdl.datasets import ingest_dataset\n",
    "\n",
    "try:\n",
    "    ingest_dataset(\"workshop_data/EuroSAT-small\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting directory: outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting files: 100%|██████████| 2/2 [00:00<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new version was created, your dataset has not changed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from eotdl.models import ingest_model\n",
    "\n",
    "try:\n",
    "    ingest_model(\"outputs\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Contribution opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to ask questions now (live or through Discord) and make suggestions for future improvements.\n",
    "\n",
    "- What features concerning ingestion would you like to see?\n",
    "- What other features concerning versioning would you like to see?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
